# bigdataprinciples1_2

## Chapter One

1- What was the reason why the NoSQL systems emerged and SQL systems are not the best?
* Becuase the traditional data (SQL) systems were not able to hanlde the big amount of data generated by internet, in specific in the moment to scale the Data. Meanwhile SQL database get more and more complex in order to handle it and are not tolerant to human mistakes!

2- What is Horizontal partioning or Sharding and how does it work? 
* It's the use of multiple database servers that are spread the table around the whole servers. In specific this technique spreads the write load across multiple machines. 

### Desired Properties of Big Data System

3- Why is important to make a Big Data System Robust and again faul tolerance?
* In this case is avoid complexities in the data system making this simple including in them the immutability into the core of the Big Data System that become them innately resilient to human error by providing a clear and simple mechanusm for recovery.

4- Why is important to have low latency reads and updates in the system and how it has relation with the Scalability propierty?
* Because the system need to be able to update and propagate immediately (in a few milliseconds to few hundred) the information (or not according to the necesities) but without compromising the robustness of the system as the same time the system need to maintin performance in the face of increasing data or load by adding resources to the system (Horizontable scalable) without increase the latency.

5- Why the system need to have generalization and extensibility at the same time? 
* Because it needs to support a wide range of applications allowing an easy large-scale migrations.

6- Why are important the minimal maintenance and debuggability, and how these are related?
* In this case because in order to have a minimal maintenance your algorithms and components need to be simple in order to avoid complexity and with a simple system, is easier to debugg the problems when something goes wrong. 

### Problems with fully incremental architectures

7- What is **Compaction** and why do you need to avoid it?
* It's the action to reclaim space in order to prevent the disk from filling up by the writing and write database. You must avoid it because the reclaiming space become expensive because it has higher demand on the CPU wich dramatically lowers the performance of the machines during a time even with the posibility to cause cascading failure making overload on the rest of the cluster.

8- What does need the Batch Layer be able to do and why does it has great advantages?
* It need to store and immutable, constantly growing master dataset and compute arbitrary fuctions on that dataset. The advantages of the batch layers is that is simple to use and its batch computations are written like single.threaded programs that give you parallelism for free, it's easy to write robust and highly scalablle.

9- What is the Serving Layer, how does it work and what need to support?
* It's a specialized distributed database that load in the batch view automatically swaping when more result are available. This need to support batch updates and random reads.

10- How does work the Speed Layer and what is its difference between the Batch Layer?
* It works producing views based on data it recieves but this only looks at recent data, whereas the batch layer looks at all data at once. In addition to that the speed layer doesn't look at all the new data at once, instead it updates the realtime view as it recieves new data instead of recomputing the whole views

11- How is summarized the Lambda Architecture?
* batch view = function(all data)
* realtime view = function(realtime view, new data)
* query = function(batch view, realtime view)

12- What is *Complexity isolation*?
* It's the capacity to discard  pieces  of  the  realtime  view  as  they’re  no  longer needed, other words because they are only temporary.

## Chapter 2

1- What is the most important part of Lamda architecture must be safeguarded from corruption?:
* The master Dataset

2- Why is important to share Raw Data?
* Because with the raw data you maximize yout ability to obtain new insights, whereas summarizing, overwriting or deleting information limits what your data can tell you

3- What is *Semantic Normalization*?
* Ts  the  process  of  reshaping  free-form information into a structured form of data.

4- Why is better to save unstructure data?
* It's better to store the unstructure data because you can improve, change or renormalize your data at a later time when you need it.

5- Why is important to use immutable data and which benifits offer?
* Because with it you avoid to overwrite your data and lost them. This allow you tack each field of user information in a separate table and you tie each unit of data to a moment in time when the information is known to be true.

6- Which are the main point for the fact-based model?
* Stores your raw data as atomic facts
* Keeps the facts immutable and eternally true by using timestamps 
* Ensures each fact is identifiable so that query processing can identify duplicates

7- Which are the advantages to make facts identifiable?
* You can write the same fact to the master dataset multiple times without changing the samantics of the master dataset and your queries can filter out the duplicate facts when doing their computations.

8- Which are the benefits of the *Fact-based model* and why?
* Is queryable at any time in its history: "Updates" and "Deletes" works adding new fact with more recent time-stamps,but because no data is actually removed you can reconstruct the state of the world at the time specified by your query
* Tolerates human errors:Is achieved by simply deleting any erroneous facts.
* Handles partial information: Because any  “absent”  fact  would  be  logically  equivalent  to  NULL
* Has the advantages of both normalized and denormalized forms: By storing the information at both the batchand serving layers, you have the benefit of keeping your data in both normalized anddenormalized forms

9- 
